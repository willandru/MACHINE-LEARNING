---
title: "Regularizacion"
author: "willandru"
date: "2024-09-06"
output: html_document
---

```{r }
library(glmnet)
library(caret)
```

```{r, echo=FALSE}
carros <- read.csv2("C:/Users/willi/GITHUB/MACHINE-LEARNING/Pre-parcial/REGULARIZACION/carros2011imputado.csv")
```


```{r }
str(carros)
```
## Feature Engineering:

De la estructura de los datos se obtienen las siguientes observaciones que llevarán a transformaciones de preparación de los datos (feature engineering):

**1-** Si la variable dependiente es el precio, hay 3 precios disponibles. Usar uno de ellos como predictor del otro probablemente no tiene sentido de negocio, porque no es el tipo de característica que va a estar disponible para predecir el precio de un nuevo vehículo. Por eso, dos de ellos serán descartados (dejaremos el precio promedio)

**2-** Las variables predictoras numéricas están todas asociadas a características físicas del carro. El ID del caso debe ser retirado como variable predictora.

**3-** Existen un conjunto de datos categóricos (tipo factor en R) que debemos transformar si deseamos que se incluyan como variables predictoras. Los airbags, el tipo de tracción y de transmisión son características no numéricas del vehículo. El tipo de vehículo. y el lugar de fabricación son posibles condicionantes del precio del vehículo también. La marca (fabricante) puede resultar interesante, más aún si tenemos en cuenta que la marca es un intangible muy importante en un vehículo, y hasta ahora ninguna de las variables podía capturar directamente intangibles de los vehículos. El modelo, en cambio, es casi único por cada vehículo (hay 93 modelos) luego es casi una variable identificadora y será descartada. Todas las demás variables categóricas cada una con k categorías a incluir se convertirán en k-1 variables binarias,

Dado que existen más de 20 posibles variables predictoras para un conjunto de tan solo 97 casos, el riesgo de overfitting puede ser grande, más aún si tenemos en cuenta que vamos a crear variables binarias para múltiples variables categóricas y requerimos bases de datos de entrenamiento y validación, incrementando aún más el riesgo mencionado. Todo ello va a implicar decisiones en el modelo y su validación.

Preparemos la base de datos:

```{r }
#guardar los modelos de los carros para interpretación
carmodelos<-carros$modelo
#remover el ID, el modelo y dos de los precios
carros<-within(carros,rm(ID,modelo,precio_basico,precio_equipado))
#crear variables dummy (binarias)
set.seed(1)
carroswin<-dummyVars("~.",data=carros)
carrosfin<-as.data.frame(predict(carroswin,newdata=carros))
```


```{r }
summary(carrosfin)
```

```{r }
carrosfin2<-within(carrosfin,rm(fabricanteLexus,tipoSporty,tracciónTrasera,transmisión_manualSi,
                                `numero_de_airbagsNo tiene`,
                                `hecho_o_no_en_USAHecho fuera de USA`))
#veamos la dimension final de la base de datos
dim(carrosfin2)
```

```{r }
#retiro la variable a predecir
predictores<-cbind(as.matrix(carrosfin2[,1:27]),as.matrix(carrosfin2[,29:59]))
```

# MODELADO - MODELO

La **multicolinealidad** y la baja relación datos a variables hacen de este problema un caso complicado para las regresiones basadas en mínimos cuadrados. Obtengamos un modelo básico y observémoslo.

### Modeo Clasico

```{r }
##entrenamiento y validación 80-20
set.seed(49584)
sample <- sample.int(nrow(carrosfin2), floor(.8*nrow(carrosfin2)))
carros.train <- carrosfin2[sample, ]
carros.test <- carrosfin2[-sample, ]
```


```{r }
#haciendo el modelo
modeloaug<-lm(precio_promedio~.,data=carros.train)
summary(modeloaug)
```


```{r }
modelocarstep<-step(modeloaug,direction="both",trace=0)
summary(modelocarstep)
```

El modelo incluyó 25 variables predictoras. Observe que varias de ellas (11 en total) son no significativas. Una mirada, por ejemplo, a los coeficientes de millas por galón en ciudad y en carretera muestran que tienen signos contrarios, lo que no tiene sentido de negocio y es un clásico signo de multicolinealidad.

La cantidad de variables y la multicolinealidad generan un modelo que, a simple vista, se ve extraño.

# REGULARIZACION

Parte de la problemática es la restricción de que los estimadores deben ser insesgados, y por tanto la suma de los residuales debe ser cero. Eso puede crear una alta varianza en los estimadores, al punto de ver los resultados que observamos.

Puesto que el error en una predicción es la suma de el sesgo y la varianza de la estimación (más el error residual), permitir cierto sesgo que disminuya en mayor proporción la varianza es un mecanismo que claramente puede permitir mejores predicciones.

Para usar la librería glmnet es necesario crear matrices separadas para los predictores y la variable pendiente. En este notebook ya creamos los predictores: falta la variable dependiente

```{r }
predic.train<-cbind(as.matrix(carros.train[,1:27]),as.matrix(carros.train[,29:59]))
precio.train<-as.matrix(carros.train[,28])

predic.test<-cbind(as.matrix(carros.test[,1:27]),as.matrix(carros.test[,29:59]))
precio.test<-as.matrix(carros.test[,28])
```

# $\lambda$


Ahora vamos a crear modelos de redes elásticas para observar cómo se comportan para diversos valores del parámetro de penalización $\lambda$.

Es importante anotar que, por defecto, las variables son estandarizadas por el procedimiento.

Con alpha=1 creamos un modelo lasso (penalizado en los valores absolutos de los coeficientes o L1) y con alpha=0 un ridge (penalizado en cuadrados de los coeficientes, o L2). Con 0.5 creamos una red elástica.

El hiperparámetro $\lambda$ genera cambios importantes en los modelos, y la escogencia de su valor no siempre es fácil. Veamos, por ejemplo, cómo cambian los coeficientes de una regresión regularizada dependiendo de $\lambda$:

```{r }
fitlasso<-glmnet(predic.train,precio.train,alpha = 1)
fitridge<-glmnet(predic.train,precio.train,alpha = 0)

#ver la variacion de los coeficientes con el lambda
plot(fitlasso, xvar="lambda")
```


```{r }
plot(fitridge, xvar="lambda")
```

Se puede observar como los valores de $\lambda$ disminuyen los parámetros desde los de una regresión de mínimos cuadrados (a la izquierda) hasta una penalización alta de coeficientes y, por tanto, un alto sesgo (a la derecha). También puede verse que en el caso de lasso los parámetros se van volviendo cero de manera independiente, mientras en ridge la reducción tiende a ser general (en todos los parámetros)

# Validacion Cruzada

¿Cómo escoger lambda? Una buena manera es probar el error que $\lambda$ comete en diferentes bases de “prueba”. La idea detrás de la validación cruzada es generar múltiples bases de entrenamiento y validación, creando múltiples modelos en la base de entrenamiento y evaluándolos múltiples veces en la base de validación.

Vamos a hacerlo para el caso de Ridge inicialmente:

## VALIDACION CRUZADA : RIDGE

```{r }
foundridge<-cv.glmnet(predic.train, precio.train,alpha=0,nfolds=5)
```

```{r }
#grafico lambda vs mse
plot(foundridge)
```

```{r }
#veo los lambda minimos
foundridge$lambda.1se
```

```{r }
foundridge$lambda.min
```

Este gráfico muestra los errores promedio de cada $\lambda$, junto con sus errores estándar. El valor que minimiza esos errores en promedio es 1.77 (0.65 en el gráfico, donde se ve el logaritmo), pero se suele sugerir (Hastie lo hace) que se utilice un valor más alto, a no más de una desviación estándar del valor del error más bajo, para obtener un modelo más parsimonioso con un error similar, y evadir el overfitting.

### Analizando los resultados:

Miremos los resultados usando ese valor de $\lambda$ con una desviación estándar más: 34.83

```{r }
coef(foundridge,s=foundridge$lambda.1se)

```

Aquí los coeficientes se interpretan en el sentido de sus mayores o menores valores relativos y su signo. Por ejemplo, entre los tamaños, Midsize y small son los más importantes, el primero aumentando el precio, y el último disminuyéndolo. Entre los fabricantes, las marcas de lujo aumentan el precio (Mercedes benz, Saab, Cadillac, Audi, Infinity) mientras que marcas más populares como Hyundai o Mercury lo disminuyen. Coeficientes más cercanos a cero marcan una baja importancia de la variable.

Mucho más interpretable suele ser un Lasso, porque puede llevar a cero muchos coeficientes:

## VALIDACION CRUZADA : LASSO

```{r }
foundlasso<-cv.glmnet(predic.train, precio.train,alpha=0,nfolds=5)

#grafico lambda vs mse
plot(foundlasso)
```

```{r }
#veo los lambda minimos
foundlasso$lambda.1se
```

```{r }
coef(fitlasso,s=foundlasso$lambda.min)
```

El modelo sesgado es más simple: un aumento de precio por la relación con los caballos de fuerza y efectos por algunas marcas específicas de lujo o económicas (no todas); pequeños efectos del espacio asiento trasero, el peso, y efectos del tipo de vehiculo. Si se usa el coeficiente de una desviación estándar por encima del mínimo se tiene un modelo sin predictores.


## VALIDACION CRUZADA : ELASTIC-NET

Ahora vamos a modelar una red elástica. Vamos a probar valores de alfa dese 0.1 hasta 0.9 para observar cuál puede ser el mejor:

```{r }
# aqui hago redes elasticas de 0.1 a 0.9
for (i in 1:10){
  assign(paste("found", i, sep=""), cv.glmnet(predic.train, precio.train, nfolds=5,
                                              alpha=i/10,))}
```


```{r }
min(foundridge$cvm)

```


```{r }
min(found1$cvm)
```

```{r }
min(found2$cvm)

```

```{r }
min(found3$cvm)
```

```{r }
min(found4$cvm)
```

```{r }
min(found5$cvm)
```

```{r }
min(found6$cvm)
```

```{r }
min(found7$cvm)
```

```{r }
min(found8$cvm)
```


```{r }
min(found9$cvm)

```


```{r }
min(foundlasso$cvm)
```


```{r }
# Extraer los valores mínimos de cvm para cada modelo
min_cvm_values <- sapply(1:10, function(i) min(get(paste("found", i, sep=""))$cvm))

# Crear una tabla con los resultados
results_table <- data.frame(
  Model = paste("found", 1:10, sep=""),
  Alpha = seq(0.1, 1.0, by=0.1),
  Min_CVM = min_cvm_values
)

# Mostrar la tabla
print(results_table)
```


"Al parecer un modelo ridge y una red elástica con alpha=0.8 pueden ser buenos candidatos. Usaremos Lasso para comparar, dada su simplicidad. Creemos el modelo que nos falta: "

```{r }
elastic8<-glmnet(predic.train,precio.train,alpha = 0.8)
coef(elastic8,s=found8$lambda.1se)
```

### EVALUACION

```{r }
#red elastica
predicciones1<-predict.glmnet(elastic8, predic.test, s=elastic8$lambda.min)

#ridge
predicciones2<-predict.glmnet(fitridge, predic.test, s=foundridge$lambda.min)

#lasso
predicciones3<-predict.glmnet(fitlasso, predic.test, s=foundlasso$lambda.min)

#stepwise
predicciones4<-predict(modelocarstep,carros.test)
```


```{r }
#calcular el MSE
erroreselastic=sqrt(mean((predicciones1-precio.test[,1])^2))
erroresridge=sqrt(mean((predicciones2-precio.test[,1])^2))
erroreslasso=sqrt(mean((predicciones3-precio.test[,1])^2))
erroresstep=sqrt(mean((predicciones4-precio.test[,1])^2))
```

```{r }
erroreselastic
```

```{r }
erroresridge
```

```{r }
erroreslasso
```

```{r }
erroresstep
```

El modelo ridge resulta el mejor predictor en la base de datos de validación. Si bien no se logra una mayor parsimonia (ni el modelo step ni los modelos que llevaron coeficientes a 0 obtuvieron mejores resultados), si parece lograrse una mejor predicción. Dado que los datos están en miles de dólares, la diferencia promedio en precisión entre los dos mejores modelos esta en el orden de los US$148 por predicción (algo cercano al 6%), lo cual, dependiendo de la aplicación, puede o no resultar valioso. El modelo lasso es quizás demasiado simple y comete errores mayores, así como la red elástica, con errores entre los cientos y los miles de dólares en promedio, lo que los descarta como candidatos viables.

En el modelo step es difícil saber o entender el efecto específico de cada variable independiente, en parte por la falta de estandarización y en parte por los problemas mencionados de multicolinealidad y parte por la baja relación casos/variables. En el modelo ridge, como se explicó, el tamaño relativo y signo de los coeficientes da idea de la importancia relativa de las variables.

# Conclusión

Los modelos regularizados pueden ser una alternativa a los modelos insesgados para mejorar la predictibilidad, particularmente en entornos de baja razón casos/variables o con multicolinealidad. La interpretación de los resultados tiene cambios importantes que deben tenerse en cuenta. La idea de la regularización puede aplicarse a múltiples tipos de modelos que estén buscando minimizar una función de error, lo que la hace altamente aplicable en machine learning.